{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.dummy import DummyRegressor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df = pd.read_csv('./preprocessed_log_data.csv')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df['energy_mark'] = df['energy_mark'].apply(lambda x: 'A' if x[0]=='A' else ('none' if x[0]=='n' else 'B-G'))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df.columns"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Dropping the columns that are used to create total_monthly_rent_log\n",
    "df.drop(columns=['monthly_rent_log', 'monthly_aconto_log','deposit_log', 'prepaid_rent_log'], inplace=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Splitting the data into features and target for regression\n",
    "X_reg_no_dummies = df.drop(columns=['total_monthly_rent_log']).copy()\n",
    "y_reg = df['total_monthly_rent_log'].copy()\n",
    "\n",
    "# Splitting the data into features and target for classification\n",
    "X_cls_no_dummies = df.drop(columns=['energy_mark']).copy()\n",
    "y_cls = df['energy_mark'].copy()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Make the categorical variables into dummies\n",
    "X_reg = pd.get_dummies(X_reg_no_dummies).to_numpy()\n",
    "X_cls = pd.get_dummies(X_cls_no_dummies).to_numpy()\n",
    "\n",
    "y_reg = y_reg.to_numpy()\n",
    "y_cls = y_cls.to_numpy()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model development"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Placeholder data - load your actual data here\n",
    "X = X_reg  # Feature matrix\n",
    "y = y_reg  # Target variable\n",
    "\n",
    "# Define hyperparameter grids\n",
    "lambda_values = [100, 1000, 10000, 25000, 50000]  # Example values for regularization in Ridge\n",
    "hidden_units_values = [1, 2, 4, 8, 16, 32, 64]  # Example values for ANN hidden units\n",
    "\n",
    "# Outer cross-validation\n",
    "outer_cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "outer_results = []\n",
    "\n",
    "# Outer CV loop\n",
    "for outer_fold, (train_outer_idx, test_outer_idx) in enumerate(tqdm(outer_cv.split(X), desc=\"Outer CV\")):\n",
    "    X_train_outer, X_test_outer = X[train_outer_idx], X[test_outer_idx]\n",
    "    y_train_outer, y_test_outer = y[train_outer_idx], y[test_outer_idx]\n",
    "\n",
    "    # Standardize features based on outer train set\n",
    "    scaler = StandardScaler()\n",
    "    X_train_outer = scaler.fit_transform(X_train_outer)\n",
    "    X_test_outer = scaler.transform(X_test_outer)\n",
    "\n",
    "    # Inner cross-validation for hyperparameter tuning\n",
    "    inner_cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Initialize placeholders for best models and errors\n",
    "    best_ann_mse, best_linreg_mse = float('inf'), float('inf')\n",
    "    best_h, best_lambda = None, None\n",
    "\n",
    "    # ANN tuning\n",
    "    # Initialize dictionary to store errors for each hidden unit value across outer folds\n",
    "    hidden_units_errors = {h: [] for h in hidden_units_values}\n",
    "\n",
    "# ANN tuning\n",
    "    for h in tqdm(hidden_units_values, desc=\"ANN Tuning\"):\n",
    "        ann_mses = []\n",
    "        for train_inner_idx, val_inner_idx in inner_cv.split(X_train_outer):\n",
    "            X_train_inner, X_val_inner = X_train_outer[train_inner_idx], X_train_outer[val_inner_idx]\n",
    "            y_train_inner, y_val_inner = y[train_inner_idx], y[val_inner_idx]\n",
    "\n",
    "            # Define ANN model\n",
    "            model = lambda: nn.Sequential(\n",
    "                nn.Linear(X_train_inner.shape[1], 2*h),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(2*h, h),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(h, 1),\n",
    "            )\n",
    "            ann_model = model()\n",
    "            criterion = nn.MSELoss()\n",
    "            optimizer = optim.Adam(ann_model.parameters(), lr=0.001)\n",
    "\n",
    "            # Train the model\n",
    "            ann_model.train()\n",
    "            for epoch in range(1000):\n",
    "                optimizer.zero_grad()\n",
    "                outputs = ann_model(torch.tensor(X_train_inner, dtype=torch.float32))\n",
    "                loss = criterion(outputs, torch.tensor(y_train_inner, dtype=torch.float32).view(-1, 1))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # Validate the model\n",
    "            ann_model.eval()\n",
    "            with torch.no_grad():\n",
    "                y_pred_val = ann_model(torch.tensor(X_val_inner, dtype=torch.float32)).numpy()\n",
    "            ann_mse = mean_squared_error(y_val_inner, y_pred_val)\n",
    "            ann_mses.append(ann_mse)\n",
    "\n",
    "        avg_ann_mse = np.mean(ann_mses)\n",
    "        hidden_units_errors[h].append(avg_ann_mse)  # Store the avg MSE for each h\n",
    "\n",
    "        if avg_ann_mse < best_ann_mse:\n",
    "            best_ann_mse = avg_ann_mse\n",
    "            best_h = h\n",
    "\n",
    "    # Linear regression tuning\n",
    "    for lam in tqdm(lambda_values, desc=\"Linear Regression Tuning\"):\n",
    "        linreg_mses = []\n",
    "        for train_inner_idx, val_inner_idx in inner_cv.split(X_train_outer):\n",
    "            X_train_inner, X_val_inner = X_train_outer[train_inner_idx], X_train_outer[val_inner_idx]\n",
    "            y_train_inner, y_val_inner = y[train_inner_idx], y[val_inner_idx]\n",
    "\n",
    "            # Define linear model with regularization\n",
    "            linreg_model = Ridge(alpha=lam)\n",
    "            linreg_model.fit(X_train_inner, y_train_inner)\n",
    "            y_pred_val = linreg_model.predict(X_val_inner)\n",
    "            linreg_mse = mean_squared_error(y_val_inner, y_pred_val)\n",
    "            linreg_mses.append(linreg_mse)\n",
    "\n",
    "        avg_linreg_mse = np.mean(linreg_mses)\n",
    "        if avg_linreg_mse < best_linreg_mse:\n",
    "            best_linreg_mse = avg_linreg_mse\n",
    "            best_lambda = lam\n",
    "\n",
    "    # Train best models from inner loop on the entire outer training set\n",
    "    ann_model = model()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(ann_model.parameters(), lr=0.01)\n",
    "    ann_model.train()\n",
    "    for epoch in range(1000):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = ann_model(torch.tensor(X_train_outer, dtype=torch.float32))\n",
    "        loss = criterion(outputs, torch.tensor(y_train_outer, dtype=torch.float32).view(-1, 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    ann_model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_test_ann = ann_model(torch.tensor(X_test_outer, dtype=torch.float32)).numpy()\n",
    "    test_mse_ann = mean_squared_error(np.exp(y_test_outer)+1, np.exp(y_pred_test_ann)+1)\n",
    "\n",
    "    linreg_model = Ridge(alpha=best_lambda)\n",
    "    linreg_model.fit(X_train_outer, y_train_outer)\n",
    "    y_pred_test_linreg = linreg_model.predict(X_test_outer)\n",
    "    test_mse_linreg = mean_squared_error(np.exp(y_test_outer)+1, np.exp(y_pred_test_linreg)+1)\n",
    "\n",
    "    # Baseline model (predicting the mean)\n",
    "    baseline_model = DummyRegressor(strategy=\"mean\")\n",
    "    baseline_model.fit(X_train_outer, y_train_outer)\n",
    "    y_pred_test_baseline = baseline_model.predict(X_test_outer)\n",
    "    test_mse_baseline = mean_squared_error(np.exp(y_test_outer)+1, np.exp(y_pred_test_baseline)+1)\n",
    "\n",
    "    # Append results for this outer fold\n",
    "    outer_results.append({\n",
    "        'outer_fold': outer_fold + 1,\n",
    "        'best_h': best_h,\n",
    "        'test_mse_ann': test_mse_ann,\n",
    "        'best_lambda': best_lambda,\n",
    "        'test_mse_linreg': test_mse_linreg,\n",
    "        'test_mse_baseline': test_mse_baseline\n",
    "    })\n",
    "\n",
    "# Create a DataFrame to display results in table format\n",
    "results_df = pd.DataFrame(outer_results)\n",
    "print(results_df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "results_df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# After the outer loop, you can plot the MSEs for each hidden unit value\n",
    "for h, errors in hidden_units_errors.items():\n",
    "    plt.plot([h] * len(errors), errors, 'o', label=f'Hidden units: {h}')\n",
    "plt.xlabel(\"Hidden Units\")\n",
    "plt.ylabel(\"Mean Squared Error (MSE)\")\n",
    "plt.title(\"ANN Hidden Units vs. Validation MSE\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New attempt also with a GLM"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Define polynomial degree and lambda values for GLM\n",
    "poly_degrees = [1, 2, 3]  # 1 for linear interactions, 2 for quadratic interactions\n",
    "glm_lambda_values = [0.1, 1, 10, 100, 1000, 10000]\n",
    "outer_results = []\n",
    "# Outer CV loop\n",
    "for outer_fold, (train_outer_idx, test_outer_idx) in enumerate(tqdm(outer_cv.split(X), desc=\"Outer CV\")):\n",
    "    X_train_outer, X_test_outer = X[train_outer_idx], X[test_outer_idx]\n",
    "    y_train_outer, y_test_outer = y[train_outer_idx], y[test_outer_idx]\n",
    "\n",
    "    # Standardize features based on outer train set\n",
    "    scaler = StandardScaler()\n",
    "    X_train_outer = scaler.fit_transform(X_train_outer)\n",
    "    X_test_outer = scaler.transform(X_test_outer)\n",
    "\n",
    "    # Inner cross-validation for hyperparameter tuning\n",
    "    inner_cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Initialize placeholders for best models and errors\n",
    "    best_ann_mse, best_linreg_mse, best_glm_mse = float('inf'), float('inf'), float('inf')\n",
    "    best_h, best_lambda, best_glm_params = None, None, None\n",
    "\n",
    "    # ANN tuning\n",
    "    for h in tqdm(hidden_units_values, desc=\"ANN Tuning\"):\n",
    "        ann_mses = []\n",
    "        for train_inner_idx, val_inner_idx in inner_cv.split(X_train_outer):\n",
    "            X_train_inner, X_val_inner = X_train_outer[train_inner_idx], X_train_outer[val_inner_idx]\n",
    "            y_train_inner, y_val_inner = y[train_inner_idx], y[val_inner_idx]\n",
    "\n",
    "            # Define ANN model\n",
    "            model = lambda: nn.Sequential(\n",
    "                nn.Linear(X_train_outer.shape[1], 2 * h),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(2 * h, h),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(h, 1),\n",
    "            )\n",
    "            ann_model = model()\n",
    "            criterion = nn.MSELoss()\n",
    "            optimizer = optim.Adam(ann_model.parameters(), lr=0.001)\n",
    "\n",
    "            # Train the model\n",
    "            ann_model.train()\n",
    "            for epoch in range(1000):\n",
    "                optimizer.zero_grad()\n",
    "                outputs = ann_model(torch.tensor(X_train_inner, dtype=torch.float32))\n",
    "                loss = criterion(outputs, torch.tensor(y_train_inner, dtype=torch.float32).view(-1, 1))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # Validate the model\n",
    "            ann_model.eval()\n",
    "            with torch.no_grad():\n",
    "                y_pred_val = ann_model(torch.tensor(X_val_inner, dtype=torch.float32)).numpy()\n",
    "            ann_mse = mean_squared_error(y_val_inner, y_pred_val)\n",
    "            ann_mses.append(ann_mse)\n",
    "\n",
    "        avg_ann_mse = np.mean(ann_mses)\n",
    "        if avg_ann_mse < best_ann_mse:\n",
    "            best_ann_mse = avg_ann_mse\n",
    "            best_h = h\n",
    "\n",
    "    # Linear regression tuning\n",
    "    for lam in tqdm(lambda_values, desc=\"Linear Regression Tuning\"):\n",
    "        linreg_mses = []\n",
    "        for train_inner_idx, val_inner_idx in inner_cv.split(X_train_outer):\n",
    "            X_train_inner, X_val_inner = X_train_outer[train_inner_idx], X_train_outer[val_inner_idx]\n",
    "            y_train_inner, y_val_inner = y[train_inner_idx], y[val_inner_idx]\n",
    "\n",
    "            # Define linear model with regularization\n",
    "            linreg_model = Ridge(alpha=lam)\n",
    "            linreg_model.fit(X_train_inner, y_train_inner)\n",
    "            y_pred_val = linreg_model.predict(X_val_inner)\n",
    "            linreg_mse = mean_squared_error(y_val_inner, y_pred_val)\n",
    "            linreg_mses.append(linreg_mse)\n",
    "\n",
    "        avg_linreg_mse = np.mean(linreg_mses)\n",
    "        if avg_linreg_mse < best_linreg_mse:\n",
    "            best_linreg_mse = avg_linreg_mse\n",
    "            best_lambda = lam\n",
    "\n",
    "\n",
    "    # GLM tuning with cross-join effects\n",
    "    for degree in tqdm(poly_degrees, desc=\"GLM Tuning\"):\n",
    "        for lam in glm_lambda_values:\n",
    "            glm_mses = []\n",
    "            for train_inner_idx, val_inner_idx in inner_cv.split(X_train_outer):\n",
    "                X_train_inner, X_val_inner = X_train_outer[train_inner_idx], X_train_outer[val_inner_idx]\n",
    "                y_train_inner, y_val_inner = y[train_inner_idx], y[val_inner_idx]\n",
    "\n",
    "                # Define GLM model with cross-join interactions\n",
    "                glm_model = make_pipeline(\n",
    "                    PolynomialFeatures(degree=degree, interaction_only=True, include_bias=False),\n",
    "                    Ridge(alpha=lam)\n",
    "                )\n",
    "                glm_model.fit(X_train_inner, y_train_inner)\n",
    "                y_pred_val = glm_model.predict(X_val_inner)\n",
    "                glm_mse = mean_squared_error(y_val_inner, y_pred_val)\n",
    "                glm_mses.append(glm_mse)\n",
    "\n",
    "            avg_glm_mse = np.mean(glm_mses)\n",
    "            if avg_glm_mse < best_glm_mse:\n",
    "                best_glm_mse = avg_glm_mse\n",
    "                best_glm_params = {'degree': degree, 'lambda': lam}\n",
    "\n",
    "    # Train best models from inner loop on the entire outer training set\n",
    "    best_ann_model = lambda: nn.Sequential(\n",
    "                nn.Linear(X_train_outer.shape[1], 2 * best_h),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(2 * best_h, best_h),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(best_h, 1),\n",
    "            )\n",
    "    ann_model = best_ann_model()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(ann_model.parameters(), lr=0.01)\n",
    "    ann_model.train()\n",
    "    for epoch in range(1000):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = ann_model(torch.tensor(X_train_outer, dtype=torch.float32))\n",
    "        loss = criterion(outputs, torch.tensor(y_train_outer, dtype=torch.float32).view(-1, 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    ann_model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_test_ann = ann_model(torch.tensor(X_test_outer, dtype=torch.float32)).numpy()\n",
    "    test_mse_ann = mean_squared_error(np.exp(y_test_outer)+1, np.exp(y_pred_test_ann)+1)\n",
    "\n",
    "    #Linear model\n",
    "    linreg_model = Ridge(alpha=best_lambda)\n",
    "    linreg_model.fit(X_train_outer, y_train_outer)\n",
    "    y_pred_test_linreg = linreg_model.predict(X_test_outer)\n",
    "    test_mse_linreg = mean_squared_error(np.exp(y_test_outer)+1, np.exp(y_pred_test_linreg)+1)\n",
    "\n",
    "    # Baseline model (predicting the mean)\n",
    "    baseline_model = DummyRegressor(strategy=\"mean\")\n",
    "    baseline_model.fit(X_train_outer, y_train_outer)\n",
    "    y_pred_test_baseline = baseline_model.predict(X_test_outer)\n",
    "    test_mse_baseline = mean_squared_error(np.exp(y_test_outer)+1, np.exp(y_pred_test_baseline)+1)\n",
    "\n",
    "    # Train best GLM model on the outer training set\n",
    "    glm_model = make_pipeline(\n",
    "        PolynomialFeatures(degree=best_glm_params['degree'], interaction_only=True, include_bias=False),\n",
    "        Ridge(alpha=best_glm_params['lambda'])\n",
    "    )\n",
    "    glm_model.fit(X_train_outer, y_train_outer)\n",
    "    y_pred_test_glm = glm_model.predict(X_test_outer)\n",
    "    test_mse_glm = mean_squared_error(np.exp(y_test_outer)+1, np.exp(y_pred_test_glm)+1)\n",
    "\n",
    "    # Append results for this outer fold\n",
    "    outer_results.append({\n",
    "        'outer_fold': outer_fold + 1,\n",
    "        'best_h': best_h,\n",
    "        'test_mse_ann': test_mse_ann,\n",
    "        'best_lambda': best_lambda,\n",
    "        'test_mse_linreg': test_mse_linreg,\n",
    "        'test_mse_baseline': test_mse_baseline,\n",
    "        'best_glm_params': best_glm_params,\n",
    "        'test_mse_glm': test_mse_glm\n",
    "    })\n",
    "    print(outer_results)\n",
    "# Create a DataFrame to display results in table format\n",
    "results1_df = pd.DataFrame(outer_results)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "len(outer_results)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New attempt with MLP Regressor instead of the ANN"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Placeholder data - load your actual data here\n",
    "X = X_reg  # Feature matrix\n",
    "y = y_reg  # Target variable\n",
    "\n",
    "# Define hyperparameter grids\n",
    "lambda_values = [100, 355, 1000, 10000, 50000]  # Example values for regularization in Ridge\n",
    "hidden_units_values = [1, 2, 4, 8, 16, 32, 64]  # Example values for ANN hidden units\n",
    "\n",
    "# Outer cross-validation\n",
    "outer_cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "outer_results = []\n",
    "\n",
    "# Outer CV loop\n",
    "for outer_fold, (train_outer_idx, test_outer_idx) in enumerate(tqdm(outer_cv.split(X), desc=\"Outer CV\")):\n",
    "    X_train_outer, X_test_outer = X[train_outer_idx], X[test_outer_idx]\n",
    "    y_train_outer, y_test_outer = y[train_outer_idx], y[test_outer_idx]\n",
    "\n",
    "    # Standardize features based on outer train set\n",
    "    scaler = StandardScaler()\n",
    "    X_train_outer = scaler.fit_transform(X_train_outer)\n",
    "    X_test_outer = scaler.transform(X_test_outer)\n",
    "\n",
    "    # Inner cross-validation for hyperparameter tuning\n",
    "    inner_cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Initialize placeholders for best models and errors\n",
    "    best_ann_mse, best_linreg_mse = float('inf'), float('inf')\n",
    "    best_h, best_lambda = None, None\n",
    "\n",
    "    # ANN tuning with MLPRegressor\n",
    "    hidden_units_errors = {h: [] for h in hidden_units_values}\n",
    "\n",
    "    for h in tqdm(hidden_units_values, desc=\"ANN Tuning\"):\n",
    "        ann_mses = []\n",
    "        for train_inner_idx, val_inner_idx in inner_cv.split(X_train_outer):\n",
    "            X_train_inner, X_val_inner = X_train_outer[train_inner_idx], X_train_outer[val_inner_idx]\n",
    "            y_train_inner, y_val_inner = y[train_inner_idx], y[val_inner_idx]\n",
    "\n",
    "            # Define MLPRegressor model with hidden units\n",
    "            ann_model = MLPRegressor(hidden_layer_sizes=(h), activation='relu', solver='adam', max_iter=1000, random_state=42)\n",
    "            ann_model.fit(X_train_inner, y_train_inner)\n",
    "            y_pred_val = ann_model.predict(X_val_inner)\n",
    "            ann_mse = mean_squared_error(y_val_inner, y_pred_val)\n",
    "            ann_mses.append(ann_mse)\n",
    "\n",
    "        avg_ann_mse = np.mean(ann_mses)\n",
    "        hidden_units_errors[h].append(avg_ann_mse)\n",
    "\n",
    "        if avg_ann_mse < best_ann_mse:\n",
    "            best_ann_mse = avg_ann_mse\n",
    "            best_h = h\n",
    "\n",
    "    # Linear regression tuning\n",
    "    for lam in tqdm(lambda_values, desc=\"Linear Regression Tuning\"):\n",
    "        linreg_mses = []\n",
    "        for train_inner_idx, val_inner_idx in inner_cv.split(X_train_outer):\n",
    "            X_train_inner, X_val_inner = X_train_outer[train_inner_idx], X_train_outer[val_inner_idx]\n",
    "            y_train_inner, y_val_inner = y[train_inner_idx], y[val_inner_idx]\n",
    "\n",
    "            # Define linear model with regularization\n",
    "            linreg_model = Ridge(alpha=lam)\n",
    "            linreg_model.fit(X_train_inner, y_train_inner)\n",
    "            y_pred_val = linreg_model.predict(X_val_inner)\n",
    "            linreg_mse = mean_squared_error(y_val_inner, y_pred_val)\n",
    "            linreg_mses.append(linreg_mse)\n",
    "\n",
    "        avg_linreg_mse = np.mean(linreg_mses)\n",
    "        if avg_linreg_mse < best_linreg_mse:\n",
    "            best_linreg_mse = avg_linreg_mse\n",
    "            best_lambda = lam\n",
    "\n",
    "    # Train best MLPRegressor model from inner loop on the entire outer training set\n",
    "    ann_model = MLPRegressor(hidden_layer_sizes=(best_h), activation='relu', solver='adam', max_iter=1000, random_state=42)\n",
    "    ann_model.fit(X_train_outer, y_train_outer)\n",
    "    y_pred_test_ann = ann_model.predict(X_test_outer)\n",
    "    test_mse_ann = mean_squared_error(np.exp(y_test_outer) + 1, np.exp(y_pred_test_ann) + 1)\n",
    "\n",
    "    # Train best Ridge model from inner loop on the entire outer training set\n",
    "    linreg_model = Ridge(alpha=best_lambda)\n",
    "    linreg_model.fit(X_train_outer, y_train_outer)\n",
    "    y_pred_test_linreg = linreg_model.predict(X_test_outer)\n",
    "    test_mse_linreg = mean_squared_error(np.exp(y_test_outer) + 1, np.exp(y_pred_test_linreg) + 1)\n",
    "\n",
    "    # Baseline model (predicting the mean)\n",
    "    baseline_model = DummyRegressor(strategy=\"mean\")\n",
    "    baseline_model.fit(X_train_outer, y_train_outer)\n",
    "    y_pred_test_baseline = baseline_model.predict(X_test_outer)\n",
    "    test_mse_baseline = mean_squared_error(np.exp(y_test_outer) + 1, np.exp(y_pred_test_baseline) + 1)\n",
    "\n",
    "    # Append results for this outer fold\n",
    "    outer_results.append({\n",
    "        'outer_fold': outer_fold + 1,\n",
    "        'best_h': best_h,\n",
    "        'test_mse_ann': test_mse_ann,\n",
    "        'best_lambda': best_lambda,\n",
    "        'test_mse_linreg': test_mse_linreg,\n",
    "        'test_mse_baseline': test_mse_baseline\n",
    "    })\n",
    "\n",
    "# Create a DataFrame to display results in table format\n",
    "results_df = pd.DataFrame(outer_results)\n",
    "print(results_df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.hist(y_reg, bins=50)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format results "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "results_df.columns = ['Outer Fold', 'Best Hidden Units', 'Test MSE ANN', 'Best Lambda', 'Test MSE LinReg', 'Test MSE Baseline']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "results_df['Test MSE ANN'] = results_df['Test MSE ANN'].apply(lambda x: round(x/10**8, 2))\n",
    "\n",
    "results_df['Test MSE LinReg'] = results_df['Test MSE LinReg'].apply(lambda x: round(x/10**8, 2))\n",
    "\n",
    "results_df['Test MSE Baseline'] = results_df['Test MSE Baseline'].apply(lambda x: round(x/10**8, 2))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "results_df.to_latex()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "results1_df.iloc[20:,:]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "results_df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "pd.concat([pd.Series(np.exp(y_pred_test_ann.reshape(1,-1)[0])-1), pd.Series(np.exp(y_pred_test_linreg)-1), pd.Series(np.exp(y_pred_test_baseline)-1), pd.Series(np.exp(y_test_outer)-1)], axis=1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "# Plot y_test_outer vs y_pred_test_ann\n",
    "plt.scatter(y_test_outer, y_pred_test_ann, color='blue', alpha=0.5, label='ANN Predictions')\n",
    "\n",
    "# Plot y_test_outer vs y_pred_test_linreg\n",
    "plt.scatter(y_test_outer, y_pred_test_linreg, color='green', alpha=0.5, label='Ridge Predictions')\n",
    "\n",
    "# Plot y_test_outer vs y_pred_test_baseline\n",
    "plt.scatter(y_test_outer, y_pred_test_baseline, color='red', alpha=0.5, label='Baseline Predictions')\n",
    "\n",
    "# Plot the ideal line\n",
    "plt.plot([min(y_test_outer), max(y_test_outer)], [min(y_test_outer), max(y_test_outer)], color='black', linestyle='--', label='Ideal')\n",
    "\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('True Values vs Predicted Values')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Calculate residuals\n",
    "residuals_ann = y_test_outer - y_pred_test_ann.flatten()\n",
    "residuals_linreg = y_test_outer - y_pred_test_linreg\n",
    "residuals_baseline = y_test_outer - y_pred_test_baseline\n",
    "\n",
    "# Plot residuals\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "# Plot residuals for ANN\n",
    "plt.scatter(y_test_outer, residuals_ann, color='blue', alpha=0.5, label='ANN Residuals')\n",
    "\n",
    "# Plot residuals for Ridge Regression\n",
    "plt.scatter(y_test_outer, residuals_linreg, color='green', alpha=0.5, label='Ridge Residuals')\n",
    "\n",
    "# Plot residuals for Baseline\n",
    "plt.scatter(y_test_outer, residuals_baseline, color='red', alpha=0.5, label='Baseline Residuals')\n",
    "\n",
    "plt.axhline(y=0, color='black', linestyle='--', label='Zero Error Line')\n",
    "\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residuals vs True Values')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check best model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Define ANN model\n",
    "model = lambda h: nn.Sequential(\n",
    "    nn.Linear(X_train_inner.shape[1], 2*h),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(2*h, h),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(h, 1),\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "X_train_outer, X_test_outer = X[train_outer_idx], X[test_outer_idx]\n",
    "y_train_outer, y_test_outer = y[train_outer_idx], y[test_outer_idx]\n",
    "\n",
    "# Standardize features based on outer train set\n",
    "scaler = StandardScaler()\n",
    "X_train_outer = scaler.fit_transform(X_train_outer)\n",
    "X_test_outer = scaler.transform(X_test_outer)\n",
    "\n",
    "\n",
    "# Train best models from inner loop on the entire outer training set\n",
    "ann_model = model(64)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(ann_model.parameters(), lr=0.01)\n",
    "ann_model.train()\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = ann_model(torch.tensor(X_train_outer, dtype=torch.float32))\n",
    "    loss = criterion(outputs, torch.tensor(y_train_outer, dtype=torch.float32).view(-1, 1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "ann_model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_test_ann = ann_model(torch.tensor(X_test_outer, dtype=torch.float32)).numpy()\n",
    "test_mse_ann = mean_squared_error(np.exp(y_test_outer)+1, np.exp(y_pred_test_ann)+1)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "pred_vs_true = pd.concat([pd.DataFrame(np.exp(y_test_outer)+1), pd.DataFrame(np.exp(y_pred_test_ann)+1)], axis=1)\n",
    "pred_vs_true.columns = ['true', 'pred']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "pred_vs_true['diff'] = abs(pred_vs_true['true'] - pred_vs_true['pred'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "pred_vs_true.describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for best model with Setup II"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Define ANN model\n",
    "def create_ann_model(input_size, h):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_size, 2 * h),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(2 * h, h),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(h, 1),\n",
    "    )\n",
    "\n",
    "# Function to evaluate models\n",
    "def evaluate_models(X, y, n_splits=10, h=16, lambda_reg=50000):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    ann_errors = []\n",
    "    ridge_errors = []\n",
    "    baseline_errors = []\n",
    "    \n",
    "    # Baseline prediction (mean)\n",
    "    baseline_prediction = np.mean(y)\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Standardize features\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        # Train Ridge Regression\n",
    "        ridge_model = Ridge(alpha=lambda_reg)\n",
    "        ridge_model.fit(X_train, y_train)\n",
    "        ridge_pred = ridge_model.predict(X_test)\n",
    "        ridge_errors.append(mean_squared_error(y_test, ridge_pred))\n",
    "\n",
    "        # Train ANN\n",
    "        ann_model = create_ann_model(X_train.shape[1], h)\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(ann_model.parameters(), lr=0.01)\n",
    "        ann_model.train()\n",
    "\n",
    "        # Training Loop\n",
    "        for epoch in range(1000):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = ann_model(torch.tensor(X_train, dtype=torch.float32))\n",
    "            loss = criterion(outputs, torch.tensor(y_train, dtype=torch.float32).view(-1, 1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Evaluation\n",
    "        ann_model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred_ann = ann_model(torch.tensor(X_test, dtype=torch.float32)).numpy()\n",
    "        ann_errors.append(mean_squared_error(y_test, y_pred_ann))\n",
    "\n",
    "        # Calculate Baseline Error\n",
    "        baseline_errors.append(mean_squared_error(y_test, [baseline_prediction]*len(y_test)))\n",
    "\n",
    "    return np.array(ann_errors), np.array(ridge_errors), np.array(baseline_errors)\n",
    "\n",
    "\n",
    "# Evaluate models\n",
    "h_value = 64  # Hidden units for ANN\n",
    "lambda_value = 50000  # Regularization parameter for Ridge\n",
    "ann_errors, ridge_errors, baseline_errors = evaluate_models(X, y, h=h_value, lambda_reg=lambda_value)\n",
    "\n",
    "# Function to perform correlated t-test\n",
    "def correlated_t_test(model_a_errors, model_b_errors):\n",
    "    differences = model_a_errors - model_b_errors\n",
    "    mean_diff = np.mean(differences)\n",
    "    std_diff = np.std(differences, ddof=1)\n",
    "    J = len(differences)\n",
    "    \n",
    "    # t-statistic\n",
    "    t_stat = mean_diff / (std_diff / np.sqrt(J))\n",
    "    df = J - 1\n",
    "    p_value = 2 * stats.t.cdf(-np.abs(t_stat), df)\n",
    "    \n",
    "    # Confidence interval\n",
    "    alpha = 0.05\n",
    "    ci_low = mean_diff - stats.t.ppf(1 - alpha / 2, df) * (std_diff / np.sqrt(J))\n",
    "    ci_high = mean_diff + stats.t.ppf(1 - alpha / 2, df) * (std_diff / np.sqrt(J))\n",
    "    \n",
    "    return mean_diff, std_diff, p_value, (ci_low, ci_high)\n",
    "\n",
    "# Pairwise comparisons\n",
    "results = {}\n",
    "\n",
    "# ANN vs Ridge Regression\n",
    "results['ANN vs Ridge Regression'] = correlated_t_test(ann_errors, ridge_errors)\n",
    "\n",
    "# ANN vs Baseline\n",
    "results['ANN vs Baseline'] = correlated_t_test(ann_errors, baseline_errors)\n",
    "\n",
    "# Ridge Regression vs Baseline\n",
    "results['Ridge Regression vs Baseline'] = correlated_t_test(ridge_errors, baseline_errors)\n",
    "\n",
    "# Print results\n",
    "for comparison, (mean_diff, std_diff, p_value, ci) in results.items():\n",
    "    print(f\"{comparison}:\")\n",
    "    print(f\"  Mean Difference: {mean_diff:.4f}, Std. Dev: {std_diff:.4f}, P-Value: {p_value:.4f}\")\n",
    "    print(f\"  Confidence Interval: {ci}\")\n",
    "    print()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# from sklearn.neural_network import MLPRegressor\n",
    "# from sklearn.linear_model import Ridge\n",
    "# from sklearn.dummy import DummyRegressor\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.model_selection import KFold\n",
    "# import numpy as np\n",
    "# from scipy import stats\n",
    "\n",
    "# # Function to evaluate models using K-Fold cross-validation\n",
    "# def evaluate_models(X, y, n_splits=10, h=64, lambda_reg=50000):\n",
    "#     kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "#     ann_errors = []\n",
    "#     ridge_errors = []\n",
    "#     baseline_errors = []\n",
    "    \n",
    "#     # Baseline prediction (mean)\n",
    "#     baseline_prediction = np.mean(y)\n",
    "\n",
    "#     for train_index, test_index in kf.split(X):\n",
    "#         X_train, X_test = X[train_index], X[test_index]\n",
    "#         y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "#         # Standardize features\n",
    "#         scaler = StandardScaler()\n",
    "#         X_train = scaler.fit_transform(X_train)\n",
    "#         X_test = scaler.transform(X_test)\n",
    "\n",
    "#         # Train Ridge Regression\n",
    "#         ridge_model = Ridge(alpha=lambda_reg)\n",
    "#         ridge_model.fit(X_train, y_train)\n",
    "#         ridge_pred = ridge_model.predict(X_test)\n",
    "#         ridge_errors.append(mean_squared_error(y_test, ridge_pred))\n",
    "\n",
    "#         # Train ANN using MLPRegressor\n",
    "#         ann_model = MLPRegressor(hidden_layer_sizes=(h,), activation='relu', solver='adam', max_iter=1000, random_state=42)\n",
    "#         ann_model.fit(X_train, y_train)\n",
    "#         ann_pred = ann_model.predict(X_test)\n",
    "#         ann_errors.append(mean_squared_error(y_test, ann_pred))\n",
    "\n",
    "#         # Calculate Baseline Error\n",
    "#         baseline_errors.append(mean_squared_error(y_test, [baseline_prediction]*len(y_test)))\n",
    "\n",
    "#     return np.array(ann_errors), np.array(ridge_errors), np.array(baseline_errors)\n",
    "\n",
    "# # Evaluate models\n",
    "# h_value = 32  # Hidden units for ANN\n",
    "# lambda_value = 10000  # Regularization parameter for Ridge\n",
    "# ann_errors, ridge_errors, baseline_errors = evaluate_models(X, y, h=h_value, lambda_reg=lambda_value)\n",
    "\n",
    "# # Function to perform correlated t-test\n",
    "# def correlated_t_test(model_a_errors, model_b_errors):\n",
    "#     differences = model_a_errors - model_b_errors\n",
    "#     mean_diff = np.mean(differences)\n",
    "#     std_diff = np.std(differences, ddof=1)\n",
    "#     J = len(differences)\n",
    "    \n",
    "#     # t-statistic\n",
    "#     t_stat = mean_diff / (std_diff / np.sqrt(J))\n",
    "#     df = J - 1\n",
    "#     p_value = 2 * stats.t.cdf(-np.abs(t_stat), df)\n",
    "    \n",
    "#     # Confidence interval\n",
    "#     alpha = 0.05\n",
    "#     ci_low = mean_diff - stats.t.ppf(1 - alpha / 2, df) * (std_diff / np.sqrt(J))\n",
    "#     ci_high = mean_diff + stats.t.ppf(1 - alpha / 2, df) * (std_diff / np.sqrt(J))\n",
    "    \n",
    "#     return mean_diff, std_diff, p_value, (ci_low, ci_high)\n",
    "\n",
    "# # Pairwise comparisons\n",
    "# results = {}\n",
    "\n",
    "# # ANN vs Ridge Regression\n",
    "# results['ANN vs Ridge Regression'] = correlated_t_test(ann_errors, ridge_errors)\n",
    "\n",
    "# # ANN vs Baseline\n",
    "# results['ANN vs Baseline'] = correlated_t_test(ann_errors, baseline_errors)\n",
    "\n",
    "# # Ridge Regression vs Baseline\n",
    "# results['Ridge Regression vs Baseline'] = correlated_t_test(ridge_errors, baseline_errors)\n",
    "\n",
    "# # Print results\n",
    "# for comparison, (mean_diff, std_diff, p_value, ci) in results.items():\n",
    "#     print(f\"{comparison}:\")\n",
    "#     print(f\"  Mean Difference: {mean_diff:.4f}, Std. Dev: {std_diff:.4f}, P-Value: {p_value:.46f}\")\n",
    "#     print(f\"  Confidence Interval: {ci}\")\n",
    "#     print()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "results2 = pd.DataFrame(results, index=['Mean Difference', 'Std. Dev', 'P-Value', 'Confidence Interval'])\n",
    "results2"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dtuenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

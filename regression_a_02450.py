# -*- coding: utf-8 -*-
"""regression-a-02450.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11e7epuUtDGWQ6N6fWICx6w64gLQWb0kh
"""

import pandas as pd

df = pd.read_csv('/content/preprocessed_log_data.csv')

# Display the first few rows of the dataframe
df.head()

# Dropping the columns that are used to create total_monthly_rent_log
df.drop(columns=['monthly_rent_log', 'monthly_aconto_log'], inplace=True)

# Convert 'months_on_website' and 'availability_in' to a categorical variable
df['months_on_website'] = df['months_on_website'].astype(str)
df['availability_in'] = df['availability_in'].astype(str)

# Splitting the data into features and target for regression
X_reg_no_dummies = df.drop(columns=['total_monthly_rent_log']).copy()
y_reg = df['total_monthly_rent_log'].copy()

# Splitting the data into features and target for classification
X_cls_no_dummies = df.drop(columns=['months_on_website']).copy()
y_cls = df['months_on_website'].copy()
# Make the categorical variables into dummies
X_reg = pd.get_dummies(X_reg_no_dummies)
X_cls = pd.get_dummies(X_cls_no_dummies)

from sklearn.linear_model import Ridge
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.model_selection import cross_val_score
import numpy as np
import matplotlib.pyplot as plt

# Define a range of lambda (α) values in logarithmic scale
lambda_range = np.logspace(-5, 5, 50)
cv_errors = []

# Loop over each lambda and perform cross-validation
for alpha in lambda_range:
    # Standardize features to mean 0, standard deviation 1
    scaler = StandardScaler()
    X_reg_scaled = scaler.fit_transform(X_reg)
    ridge_model = Ridge(alpha=alpha)
    neg_mse = cross_val_score(ridge_model, X_reg_scaled, y_reg, cv=10, scoring='neg_mean_squared_error')
    cv_errors.append(-np.mean(neg_mse))  # Convert to positive MSE

# Plot the generalization error as a function of λ
plt.figure(figsize=(10, 6))
plt.plot(lambda_range, cv_errors, marker='o', linestyle='-')
plt.xscale('log')
plt.xlabel('Regularization Parameter (λ)')
plt.ylabel('Mean Cross-Validation Error (MSE)')
plt.title('Generalization Error as a Function of λ')
plt.grid(True)
plt.show()

# Identify the best λ value with the lowest cross-validation error
best_lambda = lambda_range[np.argmin(cv_errors)]
print(f'Best λ: {best_lambda}')

# Fit the final model with the best λ
best_ridge_model = Ridge(alpha=best_lambda)
best_ridge_model.fit(X_reg_scaled, y_reg)

# Retrieve coefficients and interpret the influence of each feature
coefficients = best_ridge_model.coef_
feature_names = X_reg.columns
coeff_df = pd.DataFrame({'Feature': feature_names, 'Coefficient': coefficients})
coeff_df_sorted = coeff_df.sort_values(by='Coefficient', key=abs, ascending=False)

print("Top features impacting the model:")
print(coeff_df_sorted.head(10))  # Display top 10 most impactful features